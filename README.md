# IMDB-Webscraper

## Milestone 1

Created a webscraper class using Selenium with methods to cover all necessary funtionality to navigate the webpage and collect data. The website used was IMDB and the data was collected from the top 150 best rated superhero feature films. Getting the description for each film was attempted but the xpath for where the description is contained seems to vary depending on length of description and size of window.

## Milestone 2

Changed dictionary of lists into list of dictionaries so each dictionary represents one record in the database. Webpage URL is used as a friendly ID and a v4 UUID is generated by the python uuid library. Each dictionary is saved in a different directory corresponding to the unique ID and is saved in JSON format. The film posters are also saved in the same directory in JPEG format. Directories are created using os library. Added dowload_images() method. urllib library was used to download images from the given URLs.

## Milestone 3

Added testing using the unittest python library. The download_images method has been moved outside of the sraper class. Global variables are not referenced inside the class, parameters need to be passed instead.

## Milestone 4

Used AWS S3 Bucket to store data. Used boto3 library to connect to bucket. Created and allowed user to store data in AWS RDS using sqlalchemy library. Changed main part of code so that when run the user has an options to scrape/upload/download data.

## Milestone 5

Created an AWS RDS using PostgreSQL. The program can now upload data to the RDS. Installed Docker and created a docker image. Created an EC2 instance and connected to the EC2 terminal.

Commands used in the terminal:

Connect to EC2 instance in terminal:
`ssh -i scraperkp.pem ec2-user@ec2-54-87-166-72.compute-1.amazonaws.com`

Build Docker container:
`docker build --platform linux/amd64 --no-cache -t scraper-img .`

Running container locally:
`docker run -ti --name mycontainer --rm -v myvolume:/imdb-webscraper --platform linux/amd64 scraper-img`

Pushing Docker Container to DockerHub:
`docker tag 97ca198d2e08 aliilt/imdb-webscraper`
`docker push aliilt/imdb-webscraper`

Running container on EC2:
`docker run -ti --name mycontainer --rm -v myvolume:/imdb-webscraper --platform linux/amd64 aliilt/imdb-webscraper`

## Milestone 6

Installed Prometheus and Grafana. Created a Grafana dashboard showing Prometheus metrics on the Docker container and the EC2 instance.

## Milestone 7

Created GitHub Action that builds and pushes Docker image to DockerHub. Used GitHub Secrets to store credentials. Created a cronjob on the EC2 instance which stops then runs the scraper every day at midnight.
